## í•™ìŠµ ë°©ë²•
``` python 
python app.py --dataset_path={ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” íŒŒì¼ì˜ ê²½ë¡œ} --save_path={í•™ìŠµëœ ëª¨ë¸ ì €ì¥ ê²½ë¡œ} --model_name={model.pyì— ì¡´ì¬í•˜ëŠ” ëª¨ë¸ì˜ class} --seed={ì§€ì •ëœ seed} --num_workers={GPUì˜ workersì˜ ìˆ˜}  --epochs={epoch} --batch={batch} --resize={resize} --lr={ì‹œì‘ í•™ìŠµë¥ } --eta_min={ìµœì¢… í•™ìŠµë¥ } --weight_decay={AdamWì—ì„œ ì§€ì •í•˜ëŠ” weight_decay}
```

## íŒŒì¼ êµ¬ì¡°
``` bash
ğŸ“¦model
 â”£ ğŸ“œREADME.md
 â”£ ğŸ“œapp.py
 â”£ ğŸ“œbaseline.ipynb
 â”£ ğŸ“œdataset.py
 â”£ ğŸ“œinference.ipynb
 â”£ ğŸ“œloss.py
 â”£ ğŸ“œml_decoder.py
 â”£ ğŸ“œmodels.py
 â”£ ğŸ“œtrain.py
 â”£ ğŸ“œutils.py
 â”— ğŸ“œvisualize.ipynb
```

## ëª¨ë¸
ëª¨ë¸ì€ Timmì˜ ëª¨ë¸ì„ ì‚¬ìš©í–ˆë‹¤.
ë˜í•œ, https://github.com/Alibaba-MIIL/ML_Decoder ì˜ ML_decoderì™€ ASL Lossë¥¼ ì‚¬ìš©í–ˆë‹¤.
1. Resnet50
2. Tresnet_m
3. Tresnet_m + ml_decoder
4. Efficientnetv2_s
5. Vit_tiny
6. Vit_small
7. swinv2_cr_tiny

## ìµœì¢… ëª¨ë¸
Tresnet_m + ML_decoderë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí–ˆë‹¤.
### Tresnet
Tresnetì€ Resnet50ì„ ë³€í˜•í•˜ì—¬ ì œì‘ëœ ëª¨ë¸ì´ë©° ë©”ëª¨ë¦¬ì˜ íš¨ìœ¨ì ì¸ ì‚¬ìš©ì„ ì¤‘ì ì ìœ¼ë¡œ ë‹¤ë£¨ë©° ê²½ëŸ‰í™”í•œ ëª¨ë¸ì´ë‹¤.
ì•„ë˜ ë°©ë²•ë¡ ë“¤ì„ ì ìš©í•˜ì—¬ ê²½ëŸ‰í™” ë° ì„±ëŠ¥ í–¥ìƒ ê·¸ë¦¬ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì‚¬ìš©ì„ ë³´ì—¬ì£¼ì—ˆë‹¤.
1. Space To Depth
2. Novel Block-Type Selection
3. In-Place Activated Batch Normalization
4. Optimized SE(Squeeze-and-Excitation)
5. Anti-Aliasing
![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5d19481e-89ee-4498-b63b-2d855f43687f/Untitled.png)
### ML_decoder
ê¸°ì¡´ Global Average Poolingì€ ì—¬ëŸ¬ ê°ì²´ê°€ ì¡´ì¬í•˜ëŠ” Multi-Labelì˜ ê²½ìš° ì í•©í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— Attentionì„ ì´ìš©í•˜ì—¬ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚¼ ìˆ˜ ìˆì—ˆë‹¤.

í•˜ì§€ë§Œ, ê¸°ì¡´ Transformer-Decoderë¥¼ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ ë§ì€ ìˆ˜ì˜ Classë¥¼ ê°–ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸°ì—” êµ‰ì¥íˆ í° ì—°ì‚°ëŸ‰ì´ í•„ìš”í•˜ê²Œ ëœë‹¤.

ML-DecoderëŠ” Self-Attentionì„ ì œê±°í•¨ìœ¼ë¡œì¨ ë””ì½”ë”ê°€ ì…ë ¥ ì¿¼ë¦¬ ìˆ˜ì— ëŒ€í•´ ì œê³±ì ì¸ ì˜ì¡´ì„±ì„ ì„ í˜•ìœ¼ë¡œ ì¤„ì´ë©´ì„œ ì—°ì‚° ë³µì¡ì„±ì´ íš¨ìœ¨ì ìœ¼ë¡œ ê°ì†Œí–ˆë‹¤.

ë˜í•œ, Group Decodingì„ ì´ìš©í•˜ì—¬ íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ì‚¬ìš©, ì—°ì‚° ê°ì†Œ íš¨ê³¼ë¥¼ ì–»ì„ìˆ˜ ìˆìœ¼ë©°, ê³ ì •ëœ ì¿¼ë¦¬ë¥¼ ì´ìš©í•˜ë©´ì„œ ZSL(Zero-Shot Learning)ì„ ê°€ëŠ¥í•˜ë„ë¡ í–ˆë‹¤.

### ASL Loss
# ASL Loss

ê¸°ì¡´ Class Imbalanceë¥¼ ì»¨íŠ¸ë¡¤í•˜ëŠ” Loss Functionìœ¼ë¡œëŠ” Focal Lossê°€ ìˆë‹¤.

Focal LossëŠ” Cross Entropy Lossë¥¼ ë² ì´ìŠ¤ë¡œ í•œ Loss functionìœ¼ë¡œ $\gamma$ë¥¼ ì¡°ì ˆí•˜ë©´ì„œ ë”ìš± ê·¹ì ì¸ ê°€ì¤‘ì¹˜ë¥¼ ì¤„ ìˆ˜ ìˆë‹¤.($\gamma$=0ì´ë©´ Cross Entropy Loss)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/af4d4a17-53a8-4ca8-88c7-1d04e946e23d/Untitled.png)

ì¦‰, Focal LossëŠ” í•™ìŠµí•˜ê¸° ì–´ë ¤ìš´ ë°ì´í„°ë¥¼ ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ë¥´ê²Œ ì£¼ë©´ì„œ Class Imbalanceë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì´ë‹¤.

í•˜ì§€ë§Œ, ì–´ë ¤ìš´ ë°ì´í„°ë¥¼ ê°€ì¤‘ì¹˜ì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ì£¼ê²Œ ë˜ê³ , ìƒëŒ€ì ìœ¼ë¡œ í•™ìŠµí•˜ê¸° ì‰¬ìš´ ë°ì´í„°ì˜ Lossê°€ í¬ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.

ì¦‰, í•™ìŠµí•˜ê¸° ì–´ë ¤ìš´ Negative ë°ì´í„°ë¥¼ Down-weight í•˜ì§€ë§Œ ì—¬ê¸°ì„œ ë°œìƒí•˜ëŠ” tradeoff ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì ì œì‘ì´ ëœ Loss Functionì´ Asymmetric Lossì´ë‹¤.

ASL Lossì˜ ê²½ìš° Positive, Negative ë°ì´í„°ë¥¼ ë‹¤ë¥´ê²Œ í•™ìŠµí•´ì•¼í•œë‹¤ê³  ì´ì•¼ê¸°í•œë‹¤.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/4f2fe0c0-e69d-40b2-b176-586a48aa3ac1/Untitled.png)

Focal Lossì™€ ì‹ì´ ê°™ì§€ë§Œ, ë‹¤ë¥´ë‹¤.

í•­ìƒ $r_{+}< r_{-}$ë¡œ ì„¤ì •í•˜ì—¬ Positive ë°ì´í„°ì˜ decay weightë¥¼ ë‹¤ë¥´ê²Œ í•™ìŠµí•˜ì—¬ ì–´ë ¤ìš´ Positive ë°ì´í„°ë¥¼ ì˜ í•™ìŠµë  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì´ë‹¤.

í•˜ì§€ë§Œ, ì—¬ê¸°ì„œ Imbalanceê°€ ë§¤ìš° í° ìƒí™©ì„ ê°€ì •í•œë‹¤ë©´ Negative ë°ì´í„°ë¥¼ í•™ìŠµì´ ì•ˆë˜ëŠ” ê²½ìš°ê°€ ìˆê¸° ë•Œë¬¸ì— ì´ë¥¼ ë³´ì™„í•˜ê¸°ìœ„í•´ hard thresholdingë¥¼ ì¶”ê°€í•œë‹¤.
![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c23d0e0b-a210-483e-8d6a-8fba585d44fc/Untitled.png)