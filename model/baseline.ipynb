{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from timm.models import resnet18\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "          Identity-7           [-1, 64, 32, 32]               0\n",
      "              ReLU-8           [-1, 64, 32, 32]               0\n",
      "          Identity-9           [-1, 64, 32, 32]               0\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "             ReLU-12           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-13           [-1, 64, 32, 32]               0\n",
      "           Conv2d-14           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 32, 32]             128\n",
      "         Identity-16           [-1, 64, 32, 32]               0\n",
      "             ReLU-17           [-1, 64, 32, 32]               0\n",
      "         Identity-18           [-1, 64, 32, 32]               0\n",
      "           Conv2d-19           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 32, 32]             128\n",
      "             ReLU-21           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-22           [-1, 64, 32, 32]               0\n",
      "           Conv2d-23          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-24          [-1, 128, 16, 16]             256\n",
      "         Identity-25          [-1, 128, 16, 16]               0\n",
      "             ReLU-26          [-1, 128, 16, 16]               0\n",
      "         Identity-27          [-1, 128, 16, 16]               0\n",
      "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
      "           Conv2d-30          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-31          [-1, 128, 16, 16]             256\n",
      "             ReLU-32          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-33          [-1, 128, 16, 16]               0\n",
      "           Conv2d-34          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-35          [-1, 128, 16, 16]             256\n",
      "         Identity-36          [-1, 128, 16, 16]               0\n",
      "             ReLU-37          [-1, 128, 16, 16]               0\n",
      "         Identity-38          [-1, 128, 16, 16]               0\n",
      "           Conv2d-39          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-40          [-1, 128, 16, 16]             256\n",
      "             ReLU-41          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-42          [-1, 128, 16, 16]               0\n",
      "           Conv2d-43            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-44            [-1, 256, 8, 8]             512\n",
      "         Identity-45            [-1, 256, 8, 8]               0\n",
      "             ReLU-46            [-1, 256, 8, 8]               0\n",
      "         Identity-47            [-1, 256, 8, 8]               0\n",
      "           Conv2d-48            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-49            [-1, 256, 8, 8]             512\n",
      "           Conv2d-50            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-51            [-1, 256, 8, 8]             512\n",
      "             ReLU-52            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-53            [-1, 256, 8, 8]               0\n",
      "           Conv2d-54            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-55            [-1, 256, 8, 8]             512\n",
      "         Identity-56            [-1, 256, 8, 8]               0\n",
      "             ReLU-57            [-1, 256, 8, 8]               0\n",
      "         Identity-58            [-1, 256, 8, 8]               0\n",
      "           Conv2d-59            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-60            [-1, 256, 8, 8]             512\n",
      "             ReLU-61            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-62            [-1, 256, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
      "         Identity-65            [-1, 512, 4, 4]               0\n",
      "             ReLU-66            [-1, 512, 4, 4]               0\n",
      "         Identity-67            [-1, 512, 4, 4]               0\n",
      "           Conv2d-68            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-69            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-70            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-71            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-72            [-1, 512, 4, 4]               0\n",
      "       BasicBlock-73            [-1, 512, 4, 4]               0\n",
      "           Conv2d-74            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-75            [-1, 512, 4, 4]           1,024\n",
      "         Identity-76            [-1, 512, 4, 4]               0\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "         Identity-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-80            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-81            [-1, 512, 4, 4]               0\n",
      "       BasicBlock-82            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-83            [-1, 512, 1, 1]               0\n",
      "          Flatten-84                  [-1, 512]               0\n",
      "SelectAdaptivePool2d-85                  [-1, 512]               0\n",
      "           Linear-86                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 24.27\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 69.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(pretrained=True).cuda()\n",
    "\n",
    "summary(model, (3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "import random\n",
    "\n",
    "def parse_args():\n",
    "    parser = ArgumentParser()\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--dataset_path\",\n",
    "        type=str,\n",
    "        default=\"/opt/ml/dataset\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save_path\",\n",
    "        type=str,\n",
    "        default=\"/opt/ml/level3_cv_finalproject-cv-01/model/save\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_name\",\n",
    "        type=str,\n",
    "        default=\"resnet18\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--seed\",\n",
    "        type=int,\n",
    "        default=42\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_workers\",\n",
    "        type=int,\n",
    "        default=8\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epochs\",\n",
    "        type=int,\n",
    "        default=50\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch\",\n",
    "        type=int,\n",
    "        default=16\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--accumulation_steps\",\n",
    "        type=int,\n",
    "        default=4\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr\",\n",
    "        type=float,\n",
    "        default=1e-3\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--weight_decay\",\n",
    "        type=float,\n",
    "        default=1e-3\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "def main(args):\n",
    "    '''\n",
    "    args : 기본적으로 가져와야할 매개변수를 argParser로 가져온다.\n",
    "        dataset_path\n",
    "        model_name\n",
    "        seed\n",
    "        num_workers\n",
    "        epochs\n",
    "        batch\n",
    "        lr\n",
    "        weight_decay\n",
    "    '''\n",
    "    torch.cuda.empty_cache()\n",
    "    set_seed(args.seed)\n",
    "    wandb.init(project=\"final_project\", name=f\"cls_{args.model_name}\")\n",
    "\n",
    "    #TODO: set Augmentation\n",
    "    tf = A.Compose(\n",
    "        [\n",
    "            A.resize(512, 512),\n",
    "            A.normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),# Image net참고, 0을 기준으로 1의 표준편차\n",
    "        ]\n",
    "    )\n",
    "    #TODO: Load Dataset\n",
    "    #TODO: Load Model\n",
    "    #TODO: Optimizer & LR Scheduler\n",
    "    #TODO: Train & Valid\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def validation(model, criterion, valid_loader):\n",
    "    print(\"Start Validation...\")\n",
    "\n",
    "    total_loss, scores = [], []\n",
    "    for images, labels in tqdm(valid_loader, total=len(valid_loader)):\n",
    "        image, label = image.cuda(), label.cuda()\n",
    "        model.cuda()\n",
    "\n",
    "        with torch.cuda.amp.autocast_mode(enabled=True):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, label)\n",
    "        \n",
    "        score = f1_score(y_true=labels, y_pred=outputs, average='macro')\n",
    "        total_loss.append(loss)\n",
    "        scores.append(score)\n",
    "    #TODO : total_loss, scores 평균\n",
    "    return mean_loss, mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, scheduler, train_loader, valid_loader, args):\n",
    "    print(\"Start Train...\")\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "    cur_time = datetime.datetime.now()\n",
    "    best_score = 0\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        for step, (images, labels) in enumerate(train_loader):\n",
    "            image, label = images.cuda(), labels.cuda()\n",
    "            model.cuda()\n",
    "\n",
    "            with torch.cuda.amp.autocast_mode(enabled=True):\n",
    "                outputs = model(image)\n",
    "                loss = criterion(outputs, label)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            if not (step + 1) % args.accumulation_steps:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            wandb.log({\"train/LR\": args.lr, \"train/loss\": loss})\n",
    "            if not (step+1) % 20:\n",
    "                f'Duration :{cur_time - datetime.datetime.now()} | '\n",
    "                f\"Epoch [{epoch+1}/{args.epochs}], \"\n",
    "                f\"Step [{step+1}/{len(train_loader)}], \"\n",
    "                f\"Loss: {round(loss.item(),4)}\"\n",
    "                cur_time = datetime.datetime.now()\n",
    "\n",
    "        wandb.log({\"train/Epoch\": epoch+1})\n",
    "        scheduler.step()\n",
    "\n",
    "        if not (epoch+1) % 10:\n",
    "            loss, score = validation(model, criterion, valid_loader, args)\n",
    "\n",
    "            print(f\"Validation Marco-F1 Score : {score}\")\n",
    "            wandb.log({\"val/Loss\": loss, \"val/Score\": score})\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                output_path = os.path.join(args.save_path, f\"{args.model_name}_best.pth\")\n",
    "                torch.save(model, output_path)\n",
    "            output_path = os.path.join(args.save_path, f\"{args.model_name}_latest.pth\")\n",
    "            torch.save(model, output_path)\n",
    "    print(\"Finish Train!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
